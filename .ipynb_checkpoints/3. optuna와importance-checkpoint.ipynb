{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7f27b4-dea3-4af0-a3a3-63068476d73f",
   "metadata": {
    "id": "7f7f27b4-dea3-4af0-a3a3-63068476d73f"
   },
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ import + CSV ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28768a2-267c-4ab2-8780-ab1445c1bd77",
   "metadata": {
    "id": "b28768a2-267c-4ab2-8780-ab1445c1bd77"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import prince\n",
    "\n",
    "from sklearn.preprocessing import  OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train = pd.read_csv('./train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('./test.csv').drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10d52e-f326-41b8-a815-ff121aa47eff",
   "metadata": {
    "id": "9c10d52e-f326-41b8-a815-ff121aa47eff"
   },
   "source": [
    "## 2. EDA ëª¨ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8586dbfd-24eb-46a6-8f19-ee8eec7d1983",
   "metadata": {
    "id": "8586dbfd-24eb-46a6-8f19-ee8eec7d1983",
    "outputId": "763545de-83d0-4c58-c8f4-60bd6d6c4bcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_38648\\2032528879.py:125: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'].fillna(mean_value, inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_38648\\2032528879.py:131: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'].fillna(mean_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#'ì‹œìˆ  ì‹œê¸° ì½”ë“œ' ì—´ ì œê±°\n",
    "train = train.drop(columns=['ì‹œìˆ  ì‹œê¸° ì½”ë“œ'])\n",
    "test = test.drop(columns=['ì‹œìˆ  ì‹œê¸° ì½”ë“œ'])\n",
    "\n",
    "#'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜' ì—´ ì œê±°\n",
    "train = train.drop(columns=['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜'])\n",
    "test = test.drop(columns=['ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜'])\n",
    "\n",
    "#'ì‹œìˆ  ìœ í˜•' ì—´ ì œê±°\n",
    "train = train.drop(columns=['ì‹œìˆ  ìœ í˜•'])\n",
    "test = test.drop(columns=['ì‹œìˆ  ìœ í˜•'])\n",
    "\n",
    "#'íŠ¹ì • ì‹œìˆ  ìœ í˜•' ê·¸ë£¹í™”\n",
    "def categorize_treatment(treatment):\n",
    "    if pd.isna(treatment) or \"Unknown\" in treatment:\n",
    "        return \"Unknown\"\n",
    "    elif \"IVF\" in treatment:\n",
    "        return \"IVF ê¸°ë°˜\"\n",
    "    elif \"ICSI\" in treatment:\n",
    "        return \"ICSI ê¸°ë°˜\"\n",
    "    else:\n",
    "        return \"ê¸°íƒ€\"\n",
    "\n",
    "# ìƒˆë¡œìš´ ê·¸ë£¹ ì»¬ëŸ¼ ìƒì„±\n",
    "train[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"] = train[\"íŠ¹ì • ì‹œìˆ  ìœ í˜•\"].apply(categorize_treatment)\n",
    "\n",
    "#'ë°°ë€ ìœ ë„ ìœ í˜•' ì—´ ì œê±°\n",
    "train = train.drop(columns=['ë°°ë€ ìœ ë„ ìœ í˜•'])\n",
    "test = test.drop(columns=['ë°°ë€ ìœ ë„ ìœ í˜•'])\n",
    "\n",
    "#'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€' ì—´ ì œê±°\n",
    "train = train.drop(columns=['ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€'])\n",
    "test = test.drop(columns=['ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€'])\n",
    "\n",
    "# ì •ì ë©´ì—­í•™ì  ìš”ì¸ drop\n",
    "train = train.drop('ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', axis=1)\n",
    "test = test.drop('ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸', axis=1)\n",
    "\n",
    "# ë‚¨ì„± ìš”ì¸ MCA\n",
    "features_male = [\"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\", \"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\", \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\"]\n",
    "subset_train = train[features_male].copy()  # ì„ íƒí•œ featureë§Œ ì‚¬ìš©\n",
    "subset_test = test[features_male].copy()\n",
    "\n",
    "# prince ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ MCA ëª¨ë¸ í›ˆë ¨ (n_components=1ë¡œ ì°¨ì› ì¶•ì†Œ)\n",
    "mca = prince.MCA(n_components=1)\n",
    "\n",
    "# MCA ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê³  ì°¨ì› ì¶•ì†Œëœ ë°ì´í„° ì–»ê¸°\n",
    "mca_result_train = mca.fit_transform(subset_train)\n",
    "mca_result_test = mca.fit_transform(subset_test)\n",
    "\n",
    "# ê¸°ì¡´ ë‚¨ì„± ìš”ì¸ feature ì‚­ì œ\n",
    "train = train.drop(columns=features_male)\n",
    "test = test.drop(columns=features_male)\n",
    "\n",
    "# ì°¨ì› ì¶•ì†Œëœ ë°ì´í„°ë¥¼ ì›ë³¸ ë°ì´í„°ì— ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€\n",
    "train[\"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\"] = mca_result_train\n",
    "test[\"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\"] = mca_result_test\n",
    "\n",
    "# ì—¬ì„± ìš”ì¸ OR ì§„í–‰\n",
    "train['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸'] = train[['ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜', 'ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• ', 'ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ', 'ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦']].any(axis=1).astype(int)\n",
    "test['ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸'] = test[['ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜', 'ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• ', 'ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ', 'ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦']].any(axis=1).astype(int)\n",
    "\n",
    "# ë‚˜ë¨¸ì§€ ì—¬ì„± feature drop\n",
    "features_fe = ['ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜', 'ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• ', 'ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ', 'ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦']\n",
    "train = train.drop(columns = features_fe)\n",
    "test = test.drop(columns = features_fe)\n",
    "\n",
    "train[\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \"] = train[\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \"].apply(lambda x: 1 if isinstance(x, str) and \"í˜„ì¬ ì‹œìˆ ìš©\" in x else 0)\n",
    "test[\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \"] = test[\"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \"].apply(lambda x: 1 if isinstance(x, str) and \"í˜„ì¬ ì‹œìˆ ìš©\" in x else 0)\n",
    "\n",
    "# drop\n",
    "train = train.drop(columns=['IVF ì„ì‹  íšŸìˆ˜', 'IVF ì¶œì‚° íšŸìˆ˜', 'í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜', 'IVF ì‹œìˆ  íšŸìˆ˜'])\n",
    "test = test.drop(columns=['IVF ì„ì‹  íšŸìˆ˜', 'IVF ì¶œì‚° íšŸìˆ˜', 'í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜', 'IVF ì‹œìˆ  íšŸìˆ˜'])\n",
    "\n",
    "# feature 53 ~ 62 ì „ì²˜ë¦¬ ì§„í–‰\n",
    "\n",
    "# ë‚œì ì¶œì²˜ : 'ì•Œ ìˆ˜ ì—†ìŒ' ë°ì´í„° ì‚­ì œ\n",
    "train = train[train['ë‚œì ì¶œì²˜'] != 'ì•Œ ìˆ˜ ì—†ìŒ']\n",
    "\n",
    "test = test[test['ë‚œì ì¶œì²˜'] != 'ì•Œ ìˆ˜ ì—†ìŒ']\n",
    "\n",
    "# ì •ì ì¶œì²˜ : 'ë¯¸í• ë‹¹', 'ë°°ìš°ì ì œê³µ' ë°ì´í„° ì‚­ì œ\n",
    "train = train[train['ì •ì ì¶œì²˜'] != 'ë¯¸í• ë‹¹']\n",
    "train = train[train['ì •ì ì¶œì²˜'] != 'ë°°ìš°ì ë° ê¸°ì¦ ì œê³µ']\n",
    "\n",
    "\n",
    "#drop\n",
    "train.drop(['ë‚œì ê¸°ì¦ì ë‚˜ì´'], axis=1, inplace=True)\n",
    "train.drop(['ì •ì ê¸°ì¦ì ë‚˜ì´'], axis=1, inplace=True)\n",
    "train.drop(['ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€'], axis=1, inplace=True)\n",
    "train.drop(['ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€'], axis=1, inplace=True)\n",
    "train.drop(['ëŒ€ë¦¬ëª¨ ì—¬ë¶€'], axis=1, inplace=True)\n",
    "train.drop(['PGD ì‹œìˆ  ì—¬ë¶€'], axis=1, inplace=True)\n",
    "train.drop(['PGS ì‹œìˆ  ì—¬ë¶€'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "test.drop(['ë‚œì ê¸°ì¦ì ë‚˜ì´'], axis=1, inplace=True)\n",
    "test.drop(['ì •ì ê¸°ì¦ì ë‚˜ì´'], axis=1, inplace=True)\n",
    "test.drop(['ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€'], axis=1, inplace=True)\n",
    "test.drop(['ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€'], axis=1, inplace=True)\n",
    "test.drop(['ëŒ€ë¦¬ëª¨ ì—¬ë¶€'], axis=1, inplace=True)\n",
    "test.drop(['PGD ì‹œìˆ  ì—¬ë¶€'], axis=1, inplace=True)\n",
    "test.drop(['PGS ì‹œìˆ  ì—¬ë¶€'], axis=1, inplace=True)\n",
    "\n",
    "# 'ë‚œì ì±„ì·¨ ê²½ê³¼ì¼' ì—´ ì œê±°\n",
    "train = train.drop(columns=['ë‚œì ì±„ì·¨ ê²½ê³¼ì¼'])\n",
    "test = test.drop(columns=['ë‚œì ì±„ì·¨ ê²½ê³¼ì¼'])\n",
    "\n",
    "# 'ë‚œì í•´ë™ ê²½ê³¼ì¼' ì—´ ì œê±°\n",
    "train = train.drop(columns=['ë‚œì í•´ë™ ê²½ê³¼ì¼'])\n",
    "test = test.drop(columns=['ë‚œì í•´ë™ ê²½ê³¼ì¼'])\n",
    "\n",
    "# 'ë‚œì í˜¼í•© ê²½ê³¼ì¼' ì—´ ì œê±°\n",
    "train = train.drop(columns=['ë‚œì í˜¼í•© ê²½ê³¼ì¼'])\n",
    "test = test.drop(columns=['ë‚œì í˜¼í•© ê²½ê³¼ì¼'])\n",
    "\n",
    "# 'ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'ì˜ í‰ê· ê°’ ê³„ì‚° (ê²°ì¸¡ì¹˜ëŠ” ì œì™¸í•œ ê°’ìœ¼ë¡œ í‰ê·  ê³„ì‚°), ë°˜ì˜¬ë¦¼ ì²˜ë¦¬\n",
    "mean_value = round(train['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'].mean())  # ë°˜ì˜¬ë¦¼ ì²˜ë¦¬\n",
    "\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "train['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'].fillna(mean_value, inplace=True)\n",
    "\n",
    "# 'ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'ì˜ í‰ê· ê°’ ê³„ì‚° (ê²°ì¸¡ì¹˜ëŠ” ì œì™¸í•œ ê°’ìœ¼ë¡œ í‰ê·  ê³„ì‚°), ë°˜ì˜¬ë¦¼ ì²˜ë¦¬\n",
    "mean_value = round(test['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'].mean())  # ë°˜ì˜¬ë¦¼ ì²˜ë¦¬\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "test['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'].fillna(mean_value, inplace=True)\n",
    "\n",
    "# 'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'ë³„ ë°ì´í„° ê°œìˆ˜ ì„¸ê¸°\n",
    "total_counts_5 = train['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].value_counts()\n",
    "test_total_counts_5 = test['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].value_counts()\n",
    "\n",
    "# íŠ¹ì • ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜ ê³„ì‚°\n",
    "missing_count = train['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].isna().sum()\n",
    "test_missing_count = test['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].isna().sum()\n",
    "\n",
    "# ì›ë³¸ ë°ì´í„°ì˜ ë¹„ìœ¨ ê³„ì‚°\n",
    "value_ratios = total_counts_5 / total_counts_5.sum()\n",
    "test_value_ratios = test_total_counts_5 / test_total_counts_5.sum()\n",
    "\n",
    "# ê° ê°’ì— ëŒ€í•´ ì±„ìš¸ ê°œìˆ˜ ê³„ì‚°\n",
    "fill_counts = (value_ratios * missing_count).round().astype(int)\n",
    "test_fill_counts = (test_value_ratios * test_missing_count).round().astype(int)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ìƒ˜í”Œë§\n",
    "filled_values = np.concatenate([\n",
    "    np.full(count, value) for value, count in fill_counts.items()\n",
    "])\n",
    "\n",
    "test_filled_values = np.concatenate([\n",
    "    np.full(count, value) for value, count in test_fill_counts.items()\n",
    "])\n",
    "\n",
    "# ğŸ”¹ fill_counts ì´í•©ì´ ê²°ì¸¡ì¹˜ ê°œìˆ˜ì™€ ë‹¤ë¥¸ ê²½ìš° ë³´ì •\n",
    "diff = missing_count - fill_counts.sum()\n",
    "if diff > 0:\n",
    "    extra_values = np.random.choice(fill_counts.index, diff, p=value_ratios)\n",
    "    filled_values = np.concatenate([\n",
    "        np.full(count, value) for value, count in fill_counts.items()\n",
    "    ] + [extra_values])\n",
    "elif diff < 0:\n",
    "    filled_values = np.concatenate([\n",
    "        np.full(count, value) for value, count in fill_counts.items()\n",
    "    ])\n",
    "    filled_values = np.random.choice(filled_values, missing_count, replace=False)\n",
    "\n",
    "# ğŸ”¹ test_filled_values ì²˜ë¦¬\n",
    "if test_missing_count == 0:\n",
    "    test_filled_values = np.array([])  # ë¹ˆ ë°°ì—´ ì²˜ë¦¬\n",
    "else:\n",
    "    diff = test_missing_count - test_fill_counts.sum()\n",
    "    if diff > 0:\n",
    "        extra_values = np.random.choice(test_fill_counts.index, diff, p=test_value_ratios)\n",
    "        test_filled_values = np.concatenate([\n",
    "            np.full(count, value) for value, count in test_fill_counts.items()\n",
    "        ] + [extra_values])\n",
    "    elif diff < 0:\n",
    "        test_filled_values = np.concatenate([\n",
    "            np.full(count, value) for value, count in test_fill_counts.items()\n",
    "        ])\n",
    "        test_filled_values = np.random.choice(test_filled_values, test_missing_count, replace=False)\n",
    "\n",
    "# ë°°ì—´ì„ ì„ì–´ ëœë¤ ë°°ì¹˜\n",
    "np.random.shuffle(filled_values)\n",
    "np.random.shuffle(test_filled_values)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "train.loc[train['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].isna(), 'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'] = filled_values\n",
    "test.loc[test['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'].isna(), 'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'] = test_filled_values\n",
    "\n",
    "#ë‚œì ìˆ˜, ë°°ì•„ìˆ˜ ê´€ë ¨ dropí•  columnë“¤\n",
    "columns_to_drop = [\n",
    "    'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜', 'ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜', 'ì €ì¥ëœ ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜',\n",
    "    'í•´ë™ëœ ë°°ì•„ ìˆ˜', 'í•´ë™ ë‚œì ìˆ˜', 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜', 'ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜',\n",
    "    'í˜¼í•©ëœ ë‚œì ìˆ˜', 'íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜', 'ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜'\n",
    "]\n",
    "\n",
    "train = train.drop(columns=columns_to_drop)\n",
    "test = test.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f2c80-ea05-417e-83fd-fb3683289a1e",
   "metadata": {
    "id": "4a7f2c80-ea05-417e-83fd-fb3683289a1e"
   },
   "source": [
    "trainê³¼ test dataframeì— ëŒ€í•´ ì§€ê¸ˆê¹Œì§€ì˜ EDA ê´€ë ¨ ì½”ë“œë¥¼ ì „ë¶€ ëª¨ì€ ì…€ì…ë‹ˆë‹¤\n",
    "ì¼ì¼ì´ ì½ìœ¼ë ¤ë©´ ì •ì‹  ë‚˜ê°ˆ ìˆ˜ ìˆìŒ.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca718d-9d87-44ff-83eb-06410d8e549c",
   "metadata": {
    "id": "47ca718d-9d87-44ff-83eb-06410d8e549c"
   },
   "source": [
    "## 3. EDA í›„ì²˜ë¦¬ (ë‚¨ì€ ê²°ì¸¡ì¹˜ 0ìœ¼ë¡œ ë§Œë“¤ê¸° + ë²”ì£¼ì˜ ì •ìˆ˜í™”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9732b6-30fe-411b-bd44-afb5ab104f25",
   "metadata": {
    "id": "6a9732b6-30fe-411b-bd44-afb5ab104f25"
   },
   "outputs": [],
   "source": [
    "X = train.drop('ì„ì‹  ì„±ê³µ ì—¬ë¶€', axis=1)\n",
    "y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']\n",
    "\n",
    "categorical_columns = [\n",
    "    \"ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´\",\n",
    "    \"íŠ¹ì • ì‹œìˆ  ìœ í˜•\",\n",
    "    \"ë°°ë€ ìê·¹ ì—¬ë¶€\",\n",
    "    \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\",\n",
    "    \"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\",\n",
    "    \"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "    \"ì´ ì‹œìˆ  íšŸìˆ˜\",\n",
    "    \"DI ì‹œìˆ  íšŸìˆ˜\",\n",
    "    \"ì´ ì„ì‹  íšŸìˆ˜\",\n",
    "    \"DI ì„ì‹  íšŸìˆ˜\",\n",
    "    \"ì´ ì¶œì‚° íšŸìˆ˜\",\n",
    "    \"DI ì¶œì‚° íšŸìˆ˜\",\n",
    "    \"ë‚œì ì¶œì²˜\",\n",
    "    \"ì •ì ì¶œì²˜\",\n",
    "    \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\n",
    "    \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\"\n",
    "]\n",
    "\n",
    "numeric_columns = [\n",
    "    \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼\",\n",
    "    \"ë°°ì•„ í•´ë™ ê²½ê³¼ì¼\"\n",
    "]\n",
    "\n",
    "# ë²”ì£¼í˜• ë°ì´í„°ì˜ ëª¨ë“  ìë£Œí˜•ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "\n",
    "# ë²”ì£¼ì˜ ì •ìˆ˜í™” (by sklearn ì „ì²˜ë¦¬)\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "# test encoding ì‹œ ê¸°ì¡´ì— ì—†ë˜ ë²”ì£¼ë¥¼ ë°œê²¬í•˜ë©´ -1ë¡œ ì²˜ë¦¬\n",
    "\n",
    "X_train_encoded = X.copy()\n",
    "X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "X_test_encoded = test.copy()\n",
    "X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X_train_encoded[numeric_columns] = X_train_encoded[numeric_columns].fillna(0)\n",
    "X_test_encoded[numeric_columns] = X_test_encoded[numeric_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe415ad4-4258-4bad-9088-995c99365c8e",
   "metadata": {
    "id": "fe415ad4-4258-4bad-9088-995c99365c8e"
   },
   "source": [
    "## 4. í•™ìŠµ (adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86e9d1a-7a0a-44ec-b09d-5ee12d01db6a",
   "metadata": {
    "id": "d86e9d1a-7a0a-44ec-b09d-5ee12d01db6a",
    "outputId": "9a2d9800-1e72-4ae3-db91-26dc3df8d3f8"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (87853) does not match length of index (90067)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ìƒ˜í”Œ ì œì¶œ íŒŒì¼ ë¡œë“œ ë° ì˜ˆì¸¡ í™•ë¥  ì¶”ê°€\u001b[39;00m\n\u001b[0;32m     14\u001b[0m sample_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./sample_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m sample_submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pred_proba\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\u001b[39;00m\n\u001b[0;32m     18\u001b[0m sample_submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./randomForest_250208.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (87853) does not match length of index (90067)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# RandomForestClassifier ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)  # ê¸°ë³¸ê°’ 100ê°œì˜ íŠ¸ë¦¬\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "model.fit(X_train_encoded, y)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ í™•ë¥  ì˜ˆì¸¡\n",
    "pred_proba = model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "# ìƒ˜í”Œ ì œì¶œ íŒŒì¼ ë¡œë“œ ë° ì˜ˆì¸¡ í™•ë¥  ì¶”ê°€\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['probability'] = pred_proba\n",
    "\n",
    "# ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "sample_submission.to_csv('./randomForest_250208.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f46ead-7d17-4aa0-ae4f-e44c80ea168c",
   "metadata": {
    "id": "c6f46ead-7d17-4aa0-ae4f-e44c80ea168c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

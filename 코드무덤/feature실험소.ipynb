{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b751f1d9-f53f-4726-a9c7-0ea5016e0f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import prince\n",
    "\n",
    "from sklearn.preprocessing import  OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train = pd.read_csv('./train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('./test.csv').drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb88c37-6aa3-44ee-9102-aad88c04ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'임신 시도 또는 마지막 임신 경과 연수' 열 제거\n",
    "train = train.drop(columns=['난자 해동 경과일'])\n",
    "test = test.drop(columns=['난자 해동 경과일'])\n",
    "\n",
    "#'시술 유형' 열 제거\n",
    "train = train.drop(columns=['PGS 시술 여부'])\n",
    "test = test.drop(columns=['PGS 시술 여부'])\n",
    "\n",
    "#'시술 유형' 열 제거\n",
    "train = train.drop(columns=['PGD 시술 여부'])\n",
    "test = test.drop(columns=['PGD 시술 여부'])\n",
    "\n",
    "#'시술 유형' 열 제거\n",
    "train = train.drop(columns=['착상 전 유전 검사 사용 여부'])\n",
    "test = test.drop(columns=['착상 전 유전 검사 사용 여부'])\n",
    "\n",
    "#'시술 유형' 열 제거\n",
    "train = train.drop(columns=['임신 시도 또는 마지막 임신 경과 연수'])\n",
    "test = test.drop(columns=['임신 시도 또는 마지막 임신 경과 연수'])\n",
    "\n",
    "#'시술 유형' 열 제거\n",
    "train = train.drop(columns=['배아 해동 경과일'])\n",
    "test = test.drop(columns=['배아 해동 경과일'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "467b3c98-c277-45b6-9632-d3aed768b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "# 범주형 컬럼과 수치형 컬럼 자동 추출\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_columns = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# 범주형 데이터의 모든 자료형을 문자열로 변환\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "# 범주의 정수화 (by sklearn 전처리)\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "X_train_encoded = X.copy()\n",
    "X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "X_test_encoded = test.copy()\n",
    "X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "# 결측치 처리\n",
    "#X_train_encoded[numeric_columns] = X_train_encoded[numeric_columns].fillna(0)\n",
    "#X_test_encoded[numeric_columns] = X_test_encoded[numeric_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6196ffb-ca08-44e3-9c08-5a8e1ea59386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 230715, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258349 -> initscore=-1.054567\n",
      "[LightGBM] [Info] Start training from score -1.054567\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 706\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n",
      "[LightGBM] [Info] Start training from score -1.054550\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n",
      "[LightGBM] [Info] Start training from score -1.054550\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 698\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 701\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 702\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 697\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 695\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 696\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "ROC score: 0.7392502150\n"
     ]
    }
   ],
   "source": [
    "# 1. 라이브러리 import\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# 2. Stratified K-Fold 설정 (데이터 불균형 고려)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "\n",
    "# 3. LightGBM 모델 설정\n",
    "model = lgb.LGBMClassifier(random_state=42, objective='binary')\n",
    "\n",
    "# 4. Cross Validation 수행 \n",
    "for train_idx, val_idx in kf.split(X_train_encoded, y):\n",
    "    X_train_part, X_val = X_train_encoded.iloc[train_idx], X_train_encoded.iloc[val_idx]\n",
    "    y_train_part, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(X_train_part, y_train_part)\n",
    "    \n",
    "    # Validation 데이터 예측 확률\n",
    "    val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # ROC-AUC 점수 계산\n",
    "    roc_auc = roc_auc_score(y_val, val_pred_proba)\n",
    "    auc_scores.append(roc_auc)\n",
    "\n",
    "# 5. 평균 ROC-AUC 점수 출력\n",
    "mean_auc = np.mean(auc_scores)\n",
    "print(f\"ROC score: {mean_auc:.10f}\") # dacon과 같이 소수점 10자리 출력!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838ff4a-015a-449c-b72d-52e86de804cd",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

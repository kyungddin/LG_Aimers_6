{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85af4d56-c6c2-478f-a7ea-06d6810b62b2",
   "metadata": {},
   "source": [
    "# Import + CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01de5732-bccd-4958-8935-8acdcf1b568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train = pd.read_csv('./train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('./test.csv').drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67101dc-baf9-4647-bc5e-8c7720730df9",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131dd8cc-f639-45be-86c3-2dea71e7764c",
   "metadata": {},
   "source": [
    "### 0. 결측치가 많은 feature 7개 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c7ab3a-bb99-44d0-93a9-bb41668e6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['임신 시도 또는 마지막 임신 경과 연수'], inplace=True)\n",
    "test.drop(columns=['임신 시도 또는 마지막 임신 경과 연수'], inplace=True)\n",
    "\n",
    "train.drop(columns=['착상 전 유전 검사 사용 여부'], inplace=True)\n",
    "test.drop(columns=['착상 전 유전 검사 사용 여부'], inplace=True)\n",
    "\n",
    "train.drop(columns=['난자 해동 경과일'], inplace=True)\n",
    "test.drop(columns=['난자 해동 경과일'], inplace=True)\n",
    "\n",
    "train.drop(columns=['배아 해동 경과일'], inplace=True)\n",
    "test.drop(columns=['배아 해동 경과일'], inplace=True)\n",
    "\n",
    "train.drop(columns=['PGS 시술 여부'], inplace=True)\n",
    "test.drop(columns=['PGS 시술 여부'], inplace=True)\n",
    "\n",
    "train.drop(columns=['PGD 시술 여부'], inplace=True)\n",
    "test.drop(columns=['PGD 시술 여부'], inplace=True)\n",
    "\n",
    "train.drop(columns=['난자 채취 경과일'], inplace=True)\n",
    "test.drop(columns=['난자 채취 경과일'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec0ad3-55d9-41e1-a47c-d3798e30fd0c",
   "metadata": {},
   "source": [
    "### 1. 난자 혼합 경과일, 배아 이식 경과일 결측치 채우기 (검토 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00290b6e-dbc1-4bf3-900b-4f6f88219300",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '배아 이식 경과일'\n",
    "b = '난자 혼합 경과일'\n",
    "\n",
    "# 배아 이식 경과일 → 최빈값 처리\n",
    "train[a] = train[a].fillna(train[a].mode().iloc[0])\n",
    "test[a] = test[a].fillna(test[a].mode().iloc[0])\n",
    "\n",
    "# 난자 혼합 경과일 → 중앙값 처리\n",
    "train[b] = train[b].fillna(train[b].median())\n",
    "test[b] = test[b].fillna(test[b].median())\n",
    "\n",
    "# 일단은 최빈값-중앙값 조합이 가장 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89906d-e0f4-4230-a433-24d3dd548358",
   "metadata": {},
   "source": [
    "난자 혼합 경과일\n",
    "0.0    201920\n",
    "1.0       488\n",
    "2.0       102\n",
    "3.0        68\n",
    "5.0        24\n",
    "6.0         8\n",
    "4.0         5\n",
    "7.0         1\n",
    "Name: count, dtype: int64\n",
    "\n",
    "배아 이식 경과일\n",
    "5.0    81459\n",
    "3.0    57924\n",
    "2.0    35078\n",
    "0.0    24904\n",
    "1.0     6053\n",
    "4.0     4504\n",
    "6.0     2773\n",
    "7.0       90\n",
    "Name: count, dtype: int64\n",
    "\n",
    "둘이 분포가 다르다..! 처리 방식을 달리 해야할 듯.. 배아 이식 경과일은 평균값, 혼합 경과일은 중앙값?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd606c-2566-4b57-ad9f-d573ff8434a1",
   "metadata": {},
   "source": [
    "### 2. 주/부 불임 원인 개수 feature 추가 (검토 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c312a22-80c4-4ae2-a3b5-2e6186ef3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"주 불임 원인 개수\"] = (\n",
    "    train[\"남성 주 불임 원인\"] + train[\"여성 주 불임 원인\"] + train[\"부부 주 불임 원인\"])\n",
    "test[\"주 불임 원인 개수\"] = (\n",
    "    test[\"남성 주 불임 원인\"] + test[\"여성 주 불임 원인\"] + test[\"부부 주 불임 원인\"])\n",
    "\n",
    "train[\"부 불임 원인 개수\"] = (\n",
    "    train[\"남성 부 불임 원인\"] + train[\"여성 부 불임 원인\"] + train[\"부부 부 불임 원인\"])\n",
    "test[\"부 불임 원인 개수\"] = (\n",
    "    test[\"남성 부 불임 원인\"] + test[\"여성 부 불임 원인\"] + test[\"부부 부 불임 원인\"])\n",
    "\n",
    "# 굳이 필요한가..? 검토 결과로는 필요해보임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cca253-c4d8-46a5-ae3f-da186db2aad7",
   "metadata": {},
   "source": [
    "### 3. 여성 요인 개수로 정리 (남성 요인은 검토 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0537fa2-731a-468c-82e3-c50a1c8ab91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"불임 원인 - 여성 요인\"] = (\n",
    "    train[\"불임 원인 - 자궁내막증\"] + train[\"불임 원인 - 자궁경부 문제\"] \n",
    "    + train[\"불임 원인 - 난관 질환\"] + train[\"불임 원인 - 배란 장애\"]\n",
    ")\n",
    "test[\"불임 원인 - 여성 요인\"] = (\n",
    "    test[\"불임 원인 - 자궁내막증\"] + test[\"불임 원인 - 자궁경부 문제\"] \n",
    "    + train[\"불임 원인 - 난관 질환\"] + test[\"불임 원인 - 배란 장애\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe4d385-4cbb-4a9c-ab32-5493b6282907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain[\"불임 원인 - 남성 요인 개수\"] = (\\n    train[\"불임 원인 - 정자 형태\"] + \\n    train[\"불임 원인 - 정자 운동성\"] + \\n    train[\"불임 원인 - 정자 면역학적 요인\"] + \\n    train[\"불임 원인 - 정자 농도\"]\\n)\\n\\ntest[\"불임 원인 - 남성 요인 개수\"] = (\\n    test[\"불임 원인 - 정자 형태\"] + \\n    test[\"불임 원인 - 정자 운동성\"] + \\n    test[\"불임 원인 - 정자 면역학적 요인\"] + \\n    test[\"불임 원인 - 정자 농도\"]\\n)\\n\\n# 굳이 필요한가..?\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train[\"불임 원인 - 남성 요인 개수\"] = (\n",
    "    train[\"불임 원인 - 정자 형태\"] + \n",
    "    train[\"불임 원인 - 정자 운동성\"] + \n",
    "    train[\"불임 원인 - 정자 면역학적 요인\"] + \n",
    "    train[\"불임 원인 - 정자 농도\"]\n",
    ")\n",
    "\n",
    "test[\"불임 원인 - 남성 요인 개수\"] = (\n",
    "    test[\"불임 원인 - 정자 형태\"] + \n",
    "    test[\"불임 원인 - 정자 운동성\"] + \n",
    "    test[\"불임 원인 - 정자 면역학적 요인\"] + \n",
    "    test[\"불임 원인 - 정자 농도\"]\n",
    ")\n",
    "\n",
    "# 굳이 필요한가..?\n",
    "\"\"\"\n",
    "\n",
    "# 해보니까 빼는 게 낫다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e2048-9016-4446-9250-091283e72af1",
   "metadata": {},
   "source": [
    "### 4. 배아/난자 수 결측치 -999 처리 (+범주화? 검토 필요) ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46de9648-2eb9-45e8-a370-5462587e48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 특성에 대해 구간 정의 및 라벨링\n",
    "embryo_bins = [0, 1, 3, 6, 11, 16, 21, float('inf')]\n",
    "embryo_labels = ['0개 (배아 동결 없음)', '1~2개 (소량 저장)', '3~5개 (보편적인 저장 수준)', \n",
    "                 '6~10개 (여러 번 이식 가능)', '11~15개 (배아가 많이 저장됨)', \n",
    "                 '16~20개 (고반응군, 다배아 보유)', '21개 이상 (극단적인 고반응)']\n",
    "\n",
    "egg_bins = [0, 1, 4, 7, 11, 16, 21, float('inf')]\n",
    "egg_labels = ['0개 (난자 채취 실패)', '1~3개 (난소 저반응, 매우 적음)', '4~6개 (난소 저반응, 적음)', \n",
    "              '7~10개 (보편적인 난자 채취 수)', '11~15개 (난소 고반응 가능성)', \n",
    "              '16~20개 (고반응, 과배란 가능성)', '21개 이상 (극단적인 난소 과반응)']\n",
    "\n",
    "embryo_creation_bins = [0, 1, 3, 6, 11, 16, 21, float('inf')]\n",
    "embryo_creation_labels = ['0개 (배아 생성 실패)', '1~2개 (저반응군)', '3~5개 (중간 반응군)', \n",
    "                          '6~10개 (적절한 배아 생성)', '11~15개 (고반응군)', \n",
    "                          '16~20개 (매우 높은 반응군)', '21개 이상 (과자극군)']\n",
    "\n",
    "total_embryo_bins = [0, 1, 3, 6, 11, 21, float('inf')]\n",
    "total_embryo_labels = ['0개 (배아 없음)', '1~2개 (저반응군)', '3~5개 (중간 반응군)', \n",
    "                       '6~10개 (고반응군)', '11~20개 (과반응 가능성)', \n",
    "                       '21개 이상 (과자극군)']\n",
    "\n",
    "stored_egg_bins = [0, 1, 4, 7, 11, float('inf')]\n",
    "stored_egg_labels = ['0개 (배아 저장 없음)', '1~3개 (매우 적음)', '4~6개 (적음)', \n",
    "                     '7~10개 (보편적인 저장량)', '11개 이상 (다량 저장)']\n",
    "\n",
    "defrosted_embryo_bins = [0, 1, 2, 4, 7, 11, float('inf')]\n",
    "defrosted_embryo_labels = ['0개 (배아 해동 안 함)', '1개 (단일 배아 해동)', '2~3개 (최소 해동)', \n",
    "                           '4~6개 (중간 해동)', '7~10개 (다수 해동)', '11개 이상 (대량 해동)']\n",
    "\n",
    "defrosted_egg_bins = [0, 1, 4, 8, 13, 21, float('inf')]\n",
    "defrosted_egg_labels = ['0개 (해동하지 않음)', '1~3개 (극소수 해동)', '4~7개 (소량 해동)', \n",
    "                        '8~12개 (일반적인 해동 범위)', '13~20개 (다수 해동)', '21개 이상 (대량 해동)']\n",
    "\n",
    "# 각 구간을 매핑하는 방법 정의\n",
    "def map_category(data, bins, labels):\n",
    "    return pd.cut(data, bins=bins, labels=labels, right=False)\n",
    "\n",
    "# 각 특성에 대해 구간화 및 매핑\n",
    "train['저장된 배아 구간'] = map_category(train['저장된 배아 수'], embryo_bins, embryo_labels)\n",
    "test['저장된 배아 구간'] = map_category(test['저장된 배아 수'], embryo_bins, embryo_labels)\n",
    "\n",
    "train['난자 채취 구간'] = map_category(train['수집된 신선 난자 수'], egg_bins, egg_labels)\n",
    "test['난자 채취 구간'] = map_category(test['수집된 신선 난자 수'], egg_bins, egg_labels)\n",
    "\n",
    "train['배아 생성 구간'] = map_category(train['미세주입에서 생성된 배아 수'], embryo_creation_bins, embryo_creation_labels)\n",
    "test['배아 생성 구간'] = map_category(test['미세주입에서 생성된 배아 수'], embryo_creation_bins, embryo_creation_labels)\n",
    "\n",
    "train['총 생성 배아 구간'] = map_category(train['총 생성 배아 수'], total_embryo_bins, total_embryo_labels)\n",
    "test['총 생성 배아 구간'] = map_category(test['총 생성 배아 수'], total_embryo_bins, total_embryo_labels)\n",
    "\n",
    "train['저장된 신선 난자 구간'] = map_category(train['저장된 신선 난자 수'], stored_egg_bins, stored_egg_labels)\n",
    "test['저장된 신선 난자 구간'] = map_category(test['저장된 신선 난자 수'], stored_egg_bins, stored_egg_labels)\n",
    "\n",
    "train['해동된 배아 구간'] = map_category(train['해동된 배아 수'], defrosted_embryo_bins, defrosted_embryo_labels)\n",
    "test['해동된 배아 구간'] = map_category(test['해동된 배아 수'], defrosted_embryo_bins, defrosted_embryo_labels)\n",
    "\n",
    "train['해동 난자 구간'] = map_category(train['해동 난자 수'], defrosted_egg_bins, defrosted_egg_labels)\n",
    "test['해동 난자 구간'] = map_category(test['해동 난자 수'], defrosted_egg_bins, defrosted_egg_labels)\n",
    "\n",
    "# 각 구간에 대한 수동 라벨 인코딩\n",
    "embryo_mapping = {\n",
    "    '0개 (배아 동결 없음)': 0,\n",
    "    '1~2개 (소량 저장)': 1,\n",
    "    '3~5개 (보편적인 저장 수준)': 2,\n",
    "    '6~10개 (여러 번 이식 가능)': 3,\n",
    "    '11~15개 (배아가 많이 저장됨)': 4,\n",
    "    '16~20개 (고반응군, 다배아 보유)': 5,\n",
    "    '21개 이상 (극단적인 고반응)': 6\n",
    "}\n",
    "\n",
    "egg_mapping = {\n",
    "    '0개 (난자 채취 실패)': 0,\n",
    "    '1~3개 (난소 저반응, 매우 적음)': 1,\n",
    "    '4~6개 (난소 저반응, 적음)': 2,\n",
    "    '7~10개 (보편적인 난자 채취 수)': 3,\n",
    "    '11~15개 (난소 고반응 가능성)': 4,\n",
    "    '16~20개 (고반응, 과배란 가능성)': 5,\n",
    "    '21개 이상 (극단적인 난소 과반응)': 6\n",
    "}\n",
    "\n",
    "embryo_creation_mapping = {\n",
    "    '0개 (배아 생성 실패)': 0,\n",
    "    '1~2개 (저반응군)': 1,\n",
    "    '3~5개 (중간 반응군)': 2,\n",
    "    '6~10개 (적절한 배아 생성)': 3,\n",
    "    '11~15개 (고반응군)': 4,\n",
    "    '16~20개 (매우 높은 반응군)': 5,\n",
    "    '21개 이상 (과자극군)': 6\n",
    "}\n",
    "\n",
    "total_embryo_mapping = {\n",
    "    '0개 (배아 없음)': 0,\n",
    "    '1~2개 (저반응군)': 1,\n",
    "    '3~5개 (중간 반응군)': 2,\n",
    "    '6~10개 (고반응군)': 3,\n",
    "    '11~20개 (과반응 가능성)': 4,\n",
    "    '21개 이상 (과자극군)': 5\n",
    "}\n",
    "\n",
    "stored_egg_mapping = {\n",
    "    '0개 (배아 저장 없음)': 0,\n",
    "    '1~3개 (매우 적음)': 1,\n",
    "    '4~6개 (적음)': 2,\n",
    "    '7~10개 (보편적인 저장량)': 3,\n",
    "    '11개 이상 (다량 저장)': 4\n",
    "}\n",
    "\n",
    "defrosted_embryo_mapping = {\n",
    "    '0개 (배아 해동 안 함)': 0,\n",
    "    '1개 (단일 배아 해동)': 1,\n",
    "    '2~3개 (최소 해동)': 2,\n",
    "    '4~6개 (중간 해동)': 3,\n",
    "    '7~10개 (다수 해동)': 4,\n",
    "    '11개 이상 (대량 해동)': 5\n",
    "}\n",
    "\n",
    "defrosted_egg_mapping = {\n",
    "    '0개 (해동하지 않음)': 0,\n",
    "    '1~3개 (극소수 해동)': 1,\n",
    "    '4~7개 (소량 해동)': 2,\n",
    "    '8~12개 (일반적인 해동 범위)': 3,\n",
    "    '13~20개 (다수 해동)': 4,\n",
    "    '21개 이상 (대량 해동)': 5\n",
    "}\n",
    "\n",
    "# 수동 라벨 인코딩을 적용하는 함수\n",
    "def apply_label_encoding(df, column_name, mapping, additional_category=None):\n",
    "    # 'Categorical' 열에 추가 범주를 허용하도록 설정\n",
    "    if additional_category is not None:\n",
    "        df[column_name] = df[column_name].cat.add_categories([additional_category])\n",
    "    \n",
    "    # 매핑 적용 후 결측치는 -1로 채우고, 수치형으로 변환\n",
    "    df[column_name] = df[column_name].map(mapping).fillna(-1).astype(float)\n",
    "\n",
    "# 수동 라벨 인코딩을 각 특성에 대해 적용\n",
    "apply_label_encoding(train, '저장된 배아 구간', embryo_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '저장된 배아 구간', embryo_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '난자 채취 구간', egg_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '난자 채취 구간', egg_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '배아 생성 구간', embryo_creation_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '배아 생성 구간', embryo_creation_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '총 생성 배아 구간', total_embryo_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '총 생성 배아 구간', total_embryo_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '저장된 신선 난자 구간', stored_egg_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '저장된 신선 난자 구간', stored_egg_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '해동된 배아 구간', defrosted_embryo_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '해동된 배아 구간', defrosted_embryo_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '해동 난자 구간', defrosted_egg_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '해동 난자 구간', defrosted_egg_mapping, additional_category=-1)\n",
    "\n",
    "# 구간화된 열을 원본 열에 넣고 구간 열 삭제하기\n",
    "train['저장된 배아 수'] = train['저장된 배아 구간']\n",
    "test['저장된 배아 수'] = test['저장된 배아 구간']\n",
    "\n",
    "train['수집된 신선 난자 수'] = train['난자 채취 구간']\n",
    "test['수집된 신선 난자 수'] = test['난자 채취 구간']\n",
    "\n",
    "train['미세주입에서 생성된 배아 수'] = train['배아 생성 구간']\n",
    "test['미세주입에서 생성된 배아 수'] = test['배아 생성 구간']\n",
    "\n",
    "train['총 생성 배아 수'] = train['총 생성 배아 구간']\n",
    "test['총 생성 배아 수'] = test['총 생성 배아 구간']\n",
    "\n",
    "train['저장된 신선 난자 수'] = train['저장된 신선 난자 구간']\n",
    "test['저장된 신선 난자 수'] = test['저장된 신선 난자 구간']\n",
    "\n",
    "train['해동된 배아 수'] = train['해동된 배아 구간']\n",
    "test['해동된 배아 수'] = test['해동된 배아 구간']\n",
    "\n",
    "train['해동 난자 수'] = train['해동 난자 구간']\n",
    "test['해동 난자 수'] = test['해동 난자 구간']\n",
    "\n",
    "# 구간 열 삭제하기\n",
    "train.drop(['저장된 배아 구간', '난자 채취 구간', '배아 생성 구간', '총 생성 배아 구간', \n",
    "            '저장된 신선 난자 구간', '해동된 배아 구간', '해동 난자 구간'], axis=1, inplace=True)\n",
    "\n",
    "test.drop(['저장된 배아 구간', '난자 채취 구간', '배아 생성 구간', '총 생성 배아 구간', \n",
    "           '저장된 신선 난자 구간', '해동된 배아 구간', '해동 난자 구간'], axis=1, inplace=True)\n",
    "\n",
    "# 새로운 특성에 대한 구간 정의 및 라벨링\n",
    "mixed_egg_bins = [0, 1, 4, 8, 13, 21, float('inf')]\n",
    "mixed_egg_labels = ['0개 (배아 생성 없음)', '1~3개 (소량 사용)', '4~7개 (일반적인 배아 생성 수)', \n",
    "                    '8~12개 (다수 배아 확보 가능)', '13~20개 (대량 사용)', '21개 이상 (과다 사용)']\n",
    "\n",
    "partner_sperm_bins = [0, 1, 4, 8, 13, 21, float('inf')]\n",
    "partner_sperm_labels = ['0개 (배아 생성 없음)', '1~3개 (소량 사용)', '4~7개 (일반적인 배아 생성 수)', \n",
    "                        '8~12개 (다수 배아 확보 가능)', '13~20개 (대량 사용)', '21개 이상 (과다 사용)']\n",
    "\n",
    "donor_sperm_bins = [0, 1, 4, 8, 13, 21, float('inf')]\n",
    "donor_sperm_labels = ['0개 (기증자 정자 사용 안 함)', '1~3개 (소량 사용)', '4~7개 (일반적인 배아 생성 시 기증자 정자 사용 범위)', \n",
    "                      '8~12개 (다수 사용)', '13~20개 (대량 사용)', '21개 이상 (과다 사용)']\n",
    "\n",
    "injected_egg_bins = [0, 1, 4, 7, 11, 16, 21, float('inf')]\n",
    "injected_egg_labels = ['0개 (배아 생성 실패)', '1~3개 (배아 생성이 매우 적음)', '4~6개 (적정 수준의 배아 생성)', \n",
    "                       '7~10개 (충분한 배아 생성)', '11~15개 (다량 배아 생성)', '16~20개 (고반응군)', \n",
    "                       '21개 이상 (극단적인 고반응)']\n",
    "\n",
    "stored_embryo_bins = [0, 1, 2, 3, 6, 11, 21, float('inf')]\n",
    "stored_embryo_labels = ['0개 (배아 없음)', '1~2개 (저반응군)', '3~5개 (중간 반응군)', '6~10개 (고반응군)', \n",
    "                        '11~15개 (다배아 보유 가능성)', '16~20개 (고반응군)', '21개 이상 (과자극군)']\n",
    "\n",
    "# 구간을 매핑하는 방법 정의\n",
    "def map_category(data, bins, labels):\n",
    "    return pd.cut(data, bins=bins, labels=labels, right=False)\n",
    "\n",
    "# 새로운 특성에 대해 구간화 및 매핑\n",
    "train['혼합된 난자 수 구간'] = map_category(train['혼합된 난자 수'], mixed_egg_bins, mixed_egg_labels)\n",
    "test['혼합된 난자 수 구간'] = map_category(test['혼합된 난자 수'], mixed_egg_bins, mixed_egg_labels)\n",
    "\n",
    "train['파트너 정자와 혼합된 난자 수 구간'] = map_category(train['파트너 정자와 혼합된 난자 수'], partner_sperm_bins, partner_sperm_labels)\n",
    "test['파트너 정자와 혼합된 난자 수 구간'] = map_category(test['파트너 정자와 혼합된 난자 수'], partner_sperm_bins, partner_sperm_labels)\n",
    "\n",
    "train['기증자 정자와 혼합된 난자 수 구간'] = map_category(train['기증자 정자와 혼합된 난자 수'], donor_sperm_bins, donor_sperm_labels)\n",
    "test['기증자 정자와 혼합된 난자 수 구간'] = map_category(test['기증자 정자와 혼합된 난자 수'], donor_sperm_bins, donor_sperm_labels)\n",
    "\n",
    "train['미세주입된 난자 수 구간'] = map_category(train['미세주입된 난자 수'], injected_egg_bins, injected_egg_labels)\n",
    "test['미세주입된 난자 수 구간'] = map_category(test['미세주입된 난자 수'], injected_egg_bins, injected_egg_labels)\n",
    "\n",
    "train['미세주입 후 저장된 배아 수 구간'] = map_category(train['미세주입 후 저장된 배아 수'], stored_embryo_bins, stored_embryo_labels)\n",
    "test['미세주입 후 저장된 배아 수 구간'] = map_category(test['미세주입 후 저장된 배아 수'], stored_embryo_bins, stored_embryo_labels)\n",
    "\n",
    "# 각 구간에 대한 수동 라벨 인코딩\n",
    "mixed_egg_mapping = {\n",
    "    '0개 (배아 생성 없음)': 0,\n",
    "    '1~3개 (소량 사용)': 1,\n",
    "    '4~7개 (일반적인 배아 생성 수)': 2,\n",
    "    '8~12개 (다수 배아 확보 가능)': 3,\n",
    "    '13~20개 (대량 사용)': 4,\n",
    "    '21개 이상 (과다 사용)': 5\n",
    "}\n",
    "\n",
    "partner_sperm_mapping = {\n",
    "    '0개 (배아 생성 없음)': 0,\n",
    "    '1~3개 (소량 사용)': 1,\n",
    "    '4~7개 (일반적인 배아 생성 수)': 2,\n",
    "    '8~12개 (다수 배아 확보 가능)': 3,\n",
    "    '13~20개 (대량 사용)': 4,\n",
    "    '21개 이상 (과다 사용)': 5\n",
    "}\n",
    "\n",
    "donor_sperm_mapping = {\n",
    "    '0개 (기증자 정자 사용 안 함)': 0,\n",
    "    '1~3개 (소량 사용)': 1,\n",
    "    '4~7개 (일반적인 배아 생성 시 기증자 정자 사용 범위)': 2,\n",
    "    '8~12개 (다수 사용)': 3,\n",
    "    '13~20개 (대량 사용)': 4,\n",
    "    '21개 이상 (과다 사용)': 5\n",
    "}\n",
    "\n",
    "injected_egg_mapping = {\n",
    "    '0개 (배아 생성 실패)': 0,\n",
    "    '1~3개 (배아 생성이 매우 적음)': 1,\n",
    "    '4~6개 (적정 수준의 배아 생성)': 2,\n",
    "    '7~10개 (충분한 배아 생성)': 3,\n",
    "    '11~15개 (다량 배아 생성)': 4,\n",
    "    '16~20개 (고반응군)': 5,\n",
    "    '21개 이상 (극단적인 고반응)': 6\n",
    "}\n",
    "\n",
    "stored_embryo_mapping = {\n",
    "    '0개 (배아 없음)': 0,\n",
    "    '1~2개 (저반응군)': 1,\n",
    "    '3~5개 (중간 반응군)': 2,\n",
    "    '6~10개 (고반응군)': 3,\n",
    "    '11~15개 (다배아 보유 가능성)': 4,\n",
    "    '16~20개 (고반응군)': 5,\n",
    "    '21개 이상 (과자극군)': 6\n",
    "}\n",
    "\n",
    "# 수동 라벨 인코딩을 적용하는 함수\n",
    "def apply_label_encoding(df, column_name, mapping, additional_category=None):\n",
    "    if additional_category is not None:\n",
    "        df[column_name] = df[column_name].cat.add_categories([additional_category])\n",
    "    df[column_name] = df[column_name].map(mapping).fillna(-1).astype(float)\n",
    "\n",
    "# 수동 라벨 인코딩을 각 특성에 대해 적용\n",
    "apply_label_encoding(train, '혼합된 난자 수 구간', mixed_egg_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '혼합된 난자 수 구간', mixed_egg_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '파트너 정자와 혼합된 난자 수 구간', partner_sperm_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '파트너 정자와 혼합된 난자 수 구간', partner_sperm_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '기증자 정자와 혼합된 난자 수 구간', donor_sperm_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '기증자 정자와 혼합된 난자 수 구간', donor_sperm_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '미세주입된 난자 수 구간', injected_egg_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '미세주입된 난자 수 구간', injected_egg_mapping, additional_category=-1)\n",
    "\n",
    "apply_label_encoding(train, '미세주입 후 저장된 배아 수 구간', stored_embryo_mapping, additional_category=-1)\n",
    "apply_label_encoding(test, '미세주입 후 저장된 배아 수 구간', stored_embryo_mapping, additional_category=-1)\n",
    "\n",
    "# 구간화된 열을 원본 열에 넣고 구간 열 삭제하기\n",
    "train['혼합된 난자 수'] = train['혼합된 난자 수 구간']\n",
    "test['혼합된 난자 수'] = test['혼합된 난자 수 구간']\n",
    "\n",
    "train['파트너 정자와 혼합된 난자 수'] = train['파트너 정자와 혼합된 난자 수 구간']\n",
    "test['파트너 정자와 혼합된 난자 수'] = test['파트너 정자와 혼합된 난자 수 구간']\n",
    "\n",
    "train['기증자 정자와 혼합된 난자 수'] = train['기증자 정자와 혼합된 난자 수 구간']\n",
    "test['기증자 정자와 혼합된 난자 수'] = test['기증자 정자와 혼합된 난자 수 구간']\n",
    "\n",
    "train['미세주입된 난자 수'] = train['미세주입된 난자 수 구간']\n",
    "test['미세주입된 난자 수'] = test['미세주입된 난자 수 구간']\n",
    "\n",
    "train['미세주입 후 저장된 배아 수'] = train['미세주입 후 저장된 배아 수 구간']\n",
    "test['미세주입 후 저장된 배아 수'] = test['미세주입 후 저장된 배아 수 구간']\n",
    "\n",
    "# 구간 열 삭제하기\n",
    "train.drop(['혼합된 난자 수 구간', '파트너 정자와 혼합된 난자 수 구간', '기증자 정자와 혼합된 난자 수 구간', \n",
    "            '미세주입된 난자 수 구간', '미세주입 후 저장된 배아 수 구간'], axis=1, inplace=True)\n",
    "\n",
    "test.drop(['혼합된 난자 수 구간', '파트너 정자와 혼합된 난자 수 구간', '기증자 정자와 혼합된 난자 수 구간', \n",
    "           '미세주입된 난자 수 구간', '미세주입 후 저장된 배아 수 구간'], axis=1, inplace=True)\n",
    "\n",
    "train['이식된 배아 수'] = train['이식된 배아 수'].fillna(-1)\n",
    "test['이식된 배아 수'] = test['이식된 배아 수'].fillna(-1)\n",
    "\n",
    "train['미세주입 배아 이식 수'] = train['미세주입 배아 이식 수'].fillna(-1)\n",
    "test['미세주입 배아 이식 수'] = test['미세주입 배아 이식 수'].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44430d39-df67-429f-9307-3cdf90e9c25b",
   "metadata": {},
   "source": [
    "### 5. 배란 유도 정상화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8bda565-17e6-4c8d-ab5c-407730b54b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9672\\1468139943.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"배란 유도 유형\"].replace([\"세트로타이드 (억제제)\", \"생식선 자극 호르몬\"], \"알 수 없음\", inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9672\\1468139943.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[\"배란 유도 유형\"].replace([\"세트로타이드 (억제제)\", \"생식선 자극 호르몬\"], \"알 수 없음\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train[\"배란 유도 유형\"].replace([\"세트로타이드 (억제제)\", \"생식선 자극 호르몬\"], \"알 수 없음\", inplace=True)\n",
    "test[\"배란 유도 유형\"].replace([\"세트로타이드 (억제제)\", \"생식선 자극 호르몬\"], \"알 수 없음\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b38ee6-2320-4ac0-9c64-ddc8dcef7aed",
   "metadata": {},
   "source": [
    "### 6. 배아 생성 주요 이유 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de836a1-2341-4733-b825-71699a356c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. '연구용' 포함 행 삭제 (결측치가 있으면 빈 문자열이므로 함께 처리)\n",
    "train = train[~train['배아 생성 주요 이유'].fillna('').str.contains('연구용')]\n",
    "test = test[~test['배아 생성 주요 이유'].fillna('').str.contains('연구용')]\n",
    "\n",
    "# 결측치 문자열 'Nan'으로 처리\n",
    "train['배아 생성 주요 이유'] = train['배아 생성 주요 이유'].fillna('Nan')\n",
    "test['배아 생성 주요 이유'] = test['배아 생성 주요 이유'].fillna('Nan')\n",
    "\n",
    "# 3. One-hot encoding: 지정된 4가지 항목에 대해 dummy 변수 생성\n",
    "reasons = ['Nan','기증용', '난자 저장용', '배아 저장용', '현재 시술용']\n",
    "\n",
    "for reason in reasons:\n",
    "    col_name = f'reason_{reason}'\n",
    "    train[col_name] = train['배아 생성 주요 이유'].apply(lambda x: 1 if isinstance(x, str) and reason in x else 0)\n",
    "    test[col_name] = test['배아 생성 주요 이유'].apply(lambda x: 1 if isinstance(x, str) and reason in x else 0)\n",
    "\n",
    "# 4. 원래 있던 '배아 생성 주요 이유' 컬럼 삭제\n",
    "train = train.drop(columns=['배아 생성 주요 이유'])\n",
    "test = test.drop(columns=['배아 생성 주요 이유'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f15a18-7561-4e8e-af91-41a4898edd41",
   "metadata": {},
   "source": [
    "### 7. 시술/임신/출산 횟수 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f34e015-d91f-4bfd-ae05-dbbc200742e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_values = ['0회', '1회', '2회', '3회', '4회', '5회', '6회 이상']\n",
    "\n",
    "## train ##\n",
    "train = train[\n",
    "    (train['총 시술 횟수'].isin(valid_values)) &\n",
    "    (train['클리닉 내 총 시술 횟수'].isin(valid_values)) &\n",
    "    (train['IVF 시술 횟수'].isin(valid_values)) &\n",
    "    (train['DI 시술 횟수'].isin(valid_values)) &\n",
    "    (train['총 출산 횟수'].isin(valid_values)) &\n",
    "    (train['IVF 출산 횟수'].isin(valid_values)) &\n",
    "    (train['DI 출산 횟수'].isin(valid_values)) &\n",
    "    (train['총 임신 횟수'].isin(valid_values)) &\n",
    "    (train['IVF 임신 횟수'].isin(valid_values)) &\n",
    "    (train['DI 임신 횟수'].isin(valid_values))\n",
    "]\n",
    "\n",
    "for col in ['총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', \n",
    "            '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수']:\n",
    "    train[col] = train[col].replace('6회 이상', '6')\n",
    "    train[col] = train[col].str.replace('회', '', regex=True).astype(int)\n",
    "\n",
    "train['총 시술 횟수'] = train['IVF 시술 횟수'] + train['DI 시술 횟수']\n",
    "\n",
    "## test ##\n",
    "test = test[\n",
    "    (test['총 시술 횟수'].isin(valid_values)) &\n",
    "    (test['클리닉 내 총 시술 횟수'].isin(valid_values)) &\n",
    "    (test['IVF 시술 횟수'].isin(valid_values)) &\n",
    "    (test['DI 시술 횟수'].isin(valid_values)) &\n",
    "    (test['총 출산 횟수'].isin(valid_values)) &\n",
    "    (test['IVF 출산 횟수'].isin(valid_values)) &\n",
    "    (test['DI 출산 횟수'].isin(valid_values)) &\n",
    "    (test['총 임신 횟수'].isin(valid_values)) &\n",
    "    (test['IVF 임신 횟수'].isin(valid_values)) &\n",
    "    (test['DI 임신 횟수'].isin(valid_values))\n",
    "]\n",
    "\n",
    "for col in ['총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', \n",
    "            '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수']:\n",
    "    test[col] = test[col].replace('6회 이상', '6')\n",
    "    test[col] = test[col].str.replace('회', '', regex=True).astype(int)\n",
    "\n",
    "test['총 시술 횟수'] = test['IVF 시술 횟수'] + test['DI 시술 횟수']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644af982-fff0-473b-b2c1-101b66ec2d3d",
   "metadata": {},
   "source": [
    "### 8. 난자/정자 출처 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96db8cde-d830-4b21-b307-dd005aefb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=[\"난자 출처\", \"정자 출처\"], dtype=int)\n",
    "test = pd.get_dummies(test, columns=[\"난자 출처\", \"정자 출처\"], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c268e0-2749-4e4e-9daf-e4d2646f7e0f",
   "metadata": {},
   "source": [
    "### 9. 난자/정자 기증자 나이 라벨 인코딩 (검토 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a19f946b-7235-4abf-ae66-c143c3ddc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9672\\3223145104.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"난자 기증자 나이\"].fillna(-1, inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9672\\3223145104.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[\"난자 기증자 나이\"].fillna(-1, inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9672\\3223145104.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"정자 기증자 나이\"].fillna(-1, inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9672\\3223145104.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[\"정자 기증자 나이\"].fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 결측치를 -1로 처리 (난자 기증자 나이, 정자 기증자 나이)\n",
    "train[\"난자 기증자 나이\"].fillna(-1, inplace=True)\n",
    "test[\"난자 기증자 나이\"].fillna(-1, inplace=True)\n",
    "\n",
    "train[\"정자 기증자 나이\"].fillna(-1, inplace=True)\n",
    "test[\"정자 기증자 나이\"].fillna(-1, inplace=True)\n",
    "\n",
    "# 라벨 인코딩 매핑 딕셔너리\n",
    "age_mapping_nanja = {\n",
    "    \"만20세 이하\": 0,\n",
    "    \"만21-25세\": 1,\n",
    "    \"만26-30세\": 2,\n",
    "    \"만31-35세\": 3,\n",
    "    \"알 수 없음\": -1\n",
    "}\n",
    "\n",
    "age_mapping_jungja = {\n",
    "    \"알 수 없음\": -1, \n",
    "    \"만21-25세\": 1,\n",
    "    \"만26-30세\": 2,\n",
    "    \"만31-35세\": 3,\n",
    "    \"만36-40세\": 4,\n",
    "    \"만41-45세\": 5,\n",
    "    \"만20세 이하\": 0,\n",
    "}\n",
    "    \n",
    "# 라벨 인코딩 적용(난자)\n",
    "train[\"난자 기증자 나이 (라벨 인코딩)\"] = train[\"난자 기증자 나이\"].map(age_mapping_nanja)\n",
    "test[\"난자 기증자 나이 (라벨 인코딩)\"] = test[\"난자 기증자 나이\"].map(age_mapping_nanja)\n",
    "\n",
    "# 원본 \"난자 기증자 나이\" 컬럼 제거(난자)\n",
    "train.drop(columns=[\"난자 기증자 나이\"], inplace=True)\n",
    "test.drop(columns=[\"난자 기증자 나이\"], inplace=True)\n",
    "\n",
    "# 라벨 인코딩 적용(정자)\n",
    "train[\"정자 기증자 나이 (라벨 인코딩)\"] = train[\"정자 기증자 나이\"].map(age_mapping_jungja)\n",
    "test[\"정자 기증자 나이 (라벨 인코딩)\"] = test[\"정자 기증자 나이\"].map(age_mapping_jungja)\n",
    "\n",
    "# 원본 \"정자 기증자 나이\" 컬럼 제거(정자)\n",
    "train.drop(columns=[\"정자 기증자 나이\"], inplace=True)\n",
    "test.drop(columns=[\"정자 기증자 나이\"], inplace=True)\n",
    "\n",
    "# 결측치와 알 수 없음을 같은 -1로 처리? -999로 처리?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2183c5-f487-4f79-920e-59a4e39934ff",
   "metadata": {},
   "source": [
    "### 10. DI 시술 관련 여부 결측치 -1로 처리 + 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5e80bd3-c8aa-4309-9dd7-b902f3e1a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 -1로 채우기\n",
    "cols_to_fill = ['신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', \n",
    "                '단일 배아 이식 여부', '착상 전 유전 진단 사용 여부', '동결 배아 사용 여부']\n",
    "\n",
    "train[cols_to_fill] = train[cols_to_fill].fillna(-1)\n",
    "test[cols_to_fill] = test[cols_to_fill].fillna(-1)\n",
    "\n",
    "# 원핫인코딩 적용\n",
    "train_encoded = pd.get_dummies(train, columns=cols_to_fill)\n",
    "test_encoded = pd.get_dummies(test, columns=cols_to_fill)\n",
    "\n",
    "# 기존 열을 삭제한 데이터프레임\n",
    "train = train_encoded\n",
    "test = test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f7842-1196-420a-80e7-71255b9bc12b",
   "metadata": {},
   "source": [
    "### 11. 특정 시술 유형 그룹화 및 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abf47fd8-513f-4015-9368-c526bcdd3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 시술 유형 그룹화 함수\n",
    "def categorize_treatment(treatment):\n",
    "    if pd.isna(treatment) or \"Unknown\" in treatment:\n",
    "        return \"Unknown\"\n",
    "    elif \"IVF\" in treatment:\n",
    "        return \"IVF 기반\"\n",
    "    elif \"ICSI\" in treatment:\n",
    "        return \"ICSI 기반\"\n",
    "    elif \"Generic DI\" in treatment or \"IUI\" in treatment or \"ICI\" in treatment or \"IVI\" in treatment:\n",
    "        return \"DI 기반\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# 특정 시술 유형 컬럼을 그룹화\n",
    "train[\"특정 시술 유형\"] = train[\"특정 시술 유형\"].apply(categorize_treatment)\n",
    "test[\"특정 시술 유형\"] = test[\"특정 시술 유형\"].apply(categorize_treatment)\n",
    "\n",
    "\n",
    "# One-Hot Encoding 수행\n",
    "train_encoded = pd.get_dummies(train[\"특정 시술 유형\"], prefix=\"시술유형\")\n",
    "test_encoded = pd.get_dummies(test[\"특정 시술 유형\"], prefix=\"시술유형\")\n",
    "\n",
    "# 기존 데이터프레임에 One-Hot Encoding된 컬럼 추가\n",
    "train = pd.concat([train, train_encoded], axis=1)\n",
    "test = pd.concat([test, test_encoded], axis=1)\n",
    "\n",
    "# 원본 \"특정 시술 유형\" 컬럼 제거 (필요 시)\n",
    "train.drop(columns=[\"특정 시술 유형\"], inplace=True)\n",
    "test.drop(columns=[\"특정 시술 유형\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345b7ab-67fd-4548-9121-21049f8a055a",
   "metadata": {},
   "source": [
    "### 12. 시술 시기 코드 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f649047-1fcd-46de-9551-17dd6c52e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_timing_code(code):\n",
    "    return \"Unknown\" if pd.isna(code) else code\n",
    "\n",
    "# 결측 처리 적용\n",
    "train[\"시술 시기 코드\"] = train[\"시술 시기 코드\"].apply(preprocess_timing_code)\n",
    "test[\"시술 시기 코드\"] = test[\"시술 시기 코드\"].apply(preprocess_timing_code)\n",
    "\n",
    "# 인코딩 적용 및 컬럼 정렬 (train/test 직접 대체)\n",
    "train = pd.get_dummies(train, columns=[\"시술 시기 코드\"], prefix=\"시술시기\")\n",
    "test = pd.get_dummies(test, columns=[\"시술 시기 코드\"], prefix=\"시술시기\")\n",
    "train, test = train.align(test, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943a1c6-2777-4f71-a42e-d83e21d501ca",
   "metadata": {},
   "source": [
    "### 13. 시술 당시 나이 결측치 -999 처리 및 라벨 인코딩 (검토 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e08be8c-5abf-4845-9c54-dbf4c95065e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 인코딩 매핑 딕셔너리 (나이가 작은 순으로 매핑)\n",
    "age_mapping_treatment = {\n",
    "    \"만18-34세\": 0,\n",
    "    \"만35-37세\": 1,\n",
    "    \"만38-39세\": 2,\n",
    "    \"만40-42세\": 3,\n",
    "    \"만43-44세\": 4,\n",
    "    \"만45-50세\": 5,\n",
    "    \"알 수 없음\": -1\n",
    "}\n",
    "\n",
    "# 라벨 인코딩 적용\n",
    "train[\"시술 당시 나이 (라벨 인코딩)\"] = train[\"시술 당시 나이\"].map(age_mapping_treatment)\n",
    "test[\"시술 당시 나이 (라벨 인코딩)\"] = test[\"시술 당시 나이\"].map(age_mapping_treatment)\n",
    "\n",
    "# 원본 \"시술 당시 나이\" 컬럼 제거\n",
    "train.drop(columns=[\"시술 당시 나이\"], inplace=True)\n",
    "test.drop(columns=[\"시술 당시 나이\"], inplace=True)\n",
    "\n",
    "# -1? -999?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d76ad-f26a-4727-906b-1d4c493217fe",
   "metadata": {},
   "source": [
    "### 불명확 불임 원인, 배란 자극 여부, 배란 유도 유형, 시술 유형 라벨 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b485ce84-f2a7-457f-9590-60f3dd4d1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns = ['불명확 불임 원인', '배란 자극 여부', '시술 유형', '배란 유도 유형']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75d703af-75a9-4f3e-93c4-5312724d98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_columns:\n",
    "    train[col] = train[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "train[label_columns] = ordinal_encoder.fit_transform(train[label_columns])\n",
    "test[label_columns] = ordinal_encoder.transform(test[label_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e7082-64a3-4590-94de-080cfce5f061",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ac811-692b-47f2-8b90-8920dd24217b",
   "metadata": {},
   "source": [
    "# X와 y로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc72031b-f4f7-4bc6-b975-d415a16d48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "test.drop(columns=['임신 성공 여부'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f538225-a0c4-4c4c-a39f-87435dd78967",
   "metadata": {},
   "source": [
    "# K-Fold 점수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cee61cda-6e0e-4477-9a98-ae622cc34e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171108\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258354 -> initscore=-1.054539\n",
      "[LightGBM] [Info] Start training from score -1.054539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:52:24] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m xgb_auc_scores\u001b[38;5;241m.\u001b[39mappend(roc_auc_score(y_val, xgb_val_pred_proba))\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# TabNet 학습\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m tabnet_model\u001b[38;5;241m.\u001b[39mfit(X_train_part\u001b[38;5;241m.\u001b[39mvalues, y_train_part\u001b[38;5;241m.\u001b[39mvalues, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, virtual_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     39\u001b[0m tabnet_val_pred_proba \u001b[38;5;241m=\u001b[39m tabnet_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val\u001b[38;5;241m.\u001b[39mvalues)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     40\u001b[0m tabnet_auc_scores\u001b[38;5;241m.\u001b[39mappend(roc_auc_score(y_val, tabnet_val_pred_proba))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:258\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[0;32m    254\u001b[0m \n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch_idx)\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch(train_dataloader)\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:489\u001b[0m, in \u001b[0;36mTabModel._train_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_begin(batch_idx)\n\u001b[1;32m--> 489\u001b[0m     batch_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch(X, y)\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_end(batch_idx, batch_logs)\n\u001b[0;32m    493\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:534\u001b[0m, in \u001b[0;36mTabModel._train_batch\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    531\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_sparse \u001b[38;5;241m*\u001b[39m M_loss\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# Perform backward pass and optimization\u001b[39;00m\n\u001b[1;32m--> 534\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_value:\n\u001b[0;32m    536\u001b[0m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    628\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\function.py:292\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m    288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    This class is used for internal autograd work. Do not use.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    293\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m        Apply method used when executing this Node during the backward\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 정준아 부탁해\n",
    "\n",
    "# 1. 라이브러리 import\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier  # TabNet 추가\n",
    "import torch\n",
    "\n",
    "# 2. Stratified K-Fold 설정 (데이터 불균형 고려)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. 모델 정의\n",
    "lgb_model = LGBMClassifier(random_state=42)\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")  # XGBoost 추가\n",
    "tabnet_model = TabNetClassifier(n_d=8, n_a=8, n_steps=3, gamma=1.3, seed=42, verbose=0)  # TabNet 추가\n",
    "\n",
    "# 4. Cross Validation 수행\n",
    "lgb_auc_scores = []\n",
    "xgb_auc_scores = []\n",
    "tabnet_auc_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X, y):\n",
    "    X_train_part, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_part, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # LightGBM 학습\n",
    "    lgb_model.fit(X_train_part, y_train_part)\n",
    "    lgb_val_pred_proba = lgb_model.predict_proba(X_val)[:, 1]\n",
    "    lgb_auc_scores.append(roc_auc_score(y_val, lgb_val_pred_proba))\n",
    "\n",
    "    # XGBoost 학습\n",
    "    xgb_model.fit(X_train_part, y_train_part)\n",
    "    xgb_val_pred_proba = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    xgb_auc_scores.append(roc_auc_score(y_val, xgb_val_pred_proba))\n",
    "\n",
    "    # TabNet 학습\n",
    "    tabnet_model.fit(X_train_part.values, y_train_part.values, max_epochs=100, batch_size=1024, virtual_batch_size=128, num_workers=0)\n",
    "    tabnet_val_pred_proba = tabnet_model.predict_proba(X_val.values)[:, 1]\n",
    "    tabnet_auc_scores.append(roc_auc_score(y_val, tabnet_val_pred_proba))\n",
    "\n",
    "# 5. 평균 ROC-AUC 점수 출력\n",
    "mean_lgb_auc = np.mean(lgb_auc_scores)\n",
    "mean_xgb_auc = np.mean(xgb_auc_scores)\n",
    "mean_tabnet_auc = np.mean(tabnet_auc_scores)\n",
    "\n",
    "print(f\"Mean ROC-AUC Score (10-Fold CV) - LightGBM: {mean_lgb_auc:.10f}\")\n",
    "print(f\"Mean ROC-AUC Score (10-Fold CV) - XGBoost: {mean_xgb_auc:.10f}\")\n",
    "print(f\"Mean ROC-AUC Score (10-Fold CV) - TabNet: {mean_tabnet_auc:.10f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f6f1514-bb86-4ec8-8602-6439630b53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171108\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258354 -> initscore=-1.054539\n",
      "[LightGBM] [Info] Start training from score -1.054539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:05:01] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258350 -> initscore=-1.054561\n",
      "[LightGBM] [Info] Start training from score -1.054561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:06:44] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258350 -> initscore=-1.054561\n",
      "[LightGBM] [Info] Start training from score -1.054561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:08:21] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258350 -> initscore=-1.054561\n",
      "[LightGBM] [Info] Start training from score -1.054561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:10:00] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258350 -> initscore=-1.054561\n",
      "[LightGBM] [Info] Start training from score -1.054561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:11:42] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258350 -> initscore=-1.054561\n",
      "[LightGBM] [Info] Start training from score -1.054561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:13:16] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258350 -> initscore=-1.054561\n",
      "[LightGBM] [Info] Start training from score -1.054561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:14:50] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258350 -> initscore=-1.054561\n",
      "[LightGBM] [Info] Start training from score -1.054561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:16:29] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 230714, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258350 -> initscore=-1.054561\n",
      "[LightGBM] [Info] Start training from score -1.054561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:18:12] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 230715, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258353 -> initscore=-1.054545\n",
      "[LightGBM] [Info] Start training from score -1.054545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:19:54] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC-AUC Score (10-Fold CV) - LightGBM: 0.7390432628\n",
      "Mean ROC-AUC Score (10-Fold CV) - XGBoost: 0.7355511627\n",
      "Mean ROC-AUC Score (10-Fold CV) - RandomForest: 0.6862895274\n"
     ]
    }
   ],
   "source": [
    "# 1. 라이브러리 import\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier  # RandomForest 추가\n",
    "\n",
    "# 2. Stratified K-Fold 설정 (데이터 불균형 고려)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. 모델 정의\n",
    "lgb_model = LGBMClassifier(random_state=42)\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")  # XGBoost 추가\n",
    "rf_model = RandomForestClassifier(random_state=42)  # RandomForest 추가\n",
    "\n",
    "# 4. Cross Validation 수행\n",
    "lgb_auc_scores = []\n",
    "xgb_auc_scores = []\n",
    "rf_auc_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X, y):\n",
    "    X_train_part, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_part, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # LightGBM 학습\n",
    "    lgb_model.fit(X_train_part, y_train_part)\n",
    "    lgb_val_pred_proba = lgb_model.predict_proba(X_val)[:, 1]\n",
    "    lgb_auc_scores.append(roc_auc_score(y_val, lgb_val_pred_proba))\n",
    "\n",
    "    # XGBoost 학습\n",
    "    xgb_model.fit(X_train_part, y_train_part)\n",
    "    xgb_val_pred_proba = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    xgb_auc_scores.append(roc_auc_score(y_val, xgb_val_pred_proba))\n",
    "\n",
    "    # RandomForest 학습\n",
    "    rf_model.fit(X_train_part, y_train_part)\n",
    "    rf_val_pred_proba = rf_model.predict_proba(X_val)[:, 1]\n",
    "    rf_auc_scores.append(roc_auc_score(y_val, rf_val_pred_proba))\n",
    "\n",
    "# 5. 평균 ROC-AUC 점수 출력\n",
    "mean_lgb_auc = np.mean(lgb_auc_scores)\n",
    "mean_xgb_auc = np.mean(xgb_auc_scores)\n",
    "mean_rf_auc = np.mean(rf_auc_scores)\n",
    "\n",
    "print(f\"Mean ROC-AUC Score (10-Fold CV) - LightGBM: {mean_lgb_auc:.10f}\")\n",
    "print(f\"Mean ROC-AUC Score (10-Fold CV) - XGBoost: {mean_xgb_auc:.10f}\")\n",
    "print(f\"Mean ROC-AUC Score (10-Fold CV) - RandomForest: {mean_rf_auc:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c495c42-2897-4e13-b69f-d7afc976e072",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8bfdc-fa3d-4c4c-b802-8da35d234a96",
   "metadata": {},
   "source": [
    "# 검토결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f56782f-cd3a-461c-b4b4-431b6aa6e39e",
   "metadata": {},
   "source": [
    "검토 전 lightGBM K-Fold(10): 0.7391835805"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2027c-a2f9-436c-a029-1faedd44e2cd",
   "metadata": {},
   "source": [
    "결측치-1일때: 0.7391835805 (똑같네..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451d67e-ccd8-4413-907b-9288d014152d",
   "metadata": {},
   "source": [
    "주/부 개수를 뺐을 때: 0.7391834618 (아 필요하구나)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bfd54-d25d-4c5c-abf4-38453e7adfba",
   "metadata": {},
   "source": [
    "최빈값-중앙값: Mean ROC-AUC Score (10-Fold CV): 0.7392498922 (오 많이 올랐어..!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859cfc15-10ac-4bfa-926b-cd00a4febcac",
   "metadata": {},
   "source": [
    "남성 요인 개수 뺐을 때: Mean ROC-AUC Score (10-Fold CV): 0.7392755190 (필요없네용~)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620e2c3b-9a7a-4544-834d-bf7278d2445e",
   "metadata": {},
   "source": [
    "이러면 데이터 처리는 완료고.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad20b95-ff3d-4944-9ecc-1bd0729fcbce",
   "metadata": {},
   "source": [
    "Mean ROC-AUC Score (10-Fold CV): 0.7387037240"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5f334-9438-4ace-aa73-5f37a16d71f9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7e697e-ee47-4a75-880b-c70152092274",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4835ebf5-5796-4ff0-af6f-cbaf1a00428a",
   "metadata": {},
   "source": [
    "기본학습 결과: Trial 49 finished with value: 0.7375054814755538 and parameters: {'num_leaves': 61, 'learning_rate': 0.012644594394797709, 'n_estimators': 186, 'max_depth': 8}. Best is trial 30 with value: 0.7391048651399312.\n",
    "Best hyperparameters: {'num_leaves': 59, 'learning_rate': 0.09399447131366363, 'n_estimators': 200, 'max_depth': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26690dde-9043-48a1-b3ca-08950c6485dd",
   "metadata": {},
   "source": [
    "기본학습 + SMOTE: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9354d-09f0-45b9-a7e1-3038ea05a249",
   "metadata": {},
   "source": [
    "# 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730ad1f-c571-4e03-8711-03f4b809d3b3",
   "metadata": {},
   "source": [
    "참고수치:\n",
    "(pred_xgb*0.7 + pred_lgb*0.3)*0.95 + pred_nn*0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada8802-26e4-450a-b8ad-cce9f61fe1e6",
   "metadata": {},
   "source": [
    "# Test에 대한 예측 및 CSV 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "601347ea-3585-422f-bdab-6cebac91f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 66228, number of negative: 190121\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 256349, number of used features: 89\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258351 -> initscore=-1.054557\n",
      "[LightGBM] [Info] Start training from score -1.054557\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델 학습 (전체 데이터 사용)\n",
    "final_model = LGBMClassifier(random_state=42)\n",
    "final_model.fit(X, y)  # 전체 데이터로 학습\n",
    "\n",
    "test_pred_proba = final_model.predict_proba(test)[:, 1]  # 양성 클래스 확률\n",
    "\n",
    "# 결과 저장\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['probability'] = test_pred_proba\n",
    "sample_submission.to_csv('./02_26_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62414a-1274-4aa1-b948-1eae1851a82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
